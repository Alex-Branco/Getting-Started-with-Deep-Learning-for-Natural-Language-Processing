{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Supervised Embedding\n",
    "We have been many embedding techniques and the unsupervised way of training embeddings seems to be a normal way of training embeddings on a domain specific corpus. then such learning is passed down to the supervised learning task by providing a dense representation of the word or sentences. In opposite to all previously learned techniques, Infersent is a supervised learning method to learn sentence level embedding. Infersent was invented by Facebook ai research team and published in a publication \"Supervised Learning of Universal Sentence Representations from Natural Language Inference Data\".  Conneau et al. noted that image net trained in a supervised way doing a great job in the downward tasks. Extending this fact Conneau et al trained sentence embedding layer on the supervised manner known as Infersent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Sax4QLDp4xus",
    "outputId": "3b7561a5-73ee-442e-eb10-19e57b8acfe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sunil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "import sys\n",
    "import torch\n",
    "import nltk\n",
    "import os\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mKnXPUb6LRIH"
   },
   "source": [
    "## Pre-requisite\n",
    "1. Clonning InferSent and adding it to system path\n",
    "2. Downloading required dataset by InferSent\n",
    "3. Downloading GloVe and FastText vectors\n",
    "4. Downloading InferSent pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "zn7MJddXyZD9",
    "outputId": "64d32841-68de-4278-a7f5-3102db6f7fdc"
   },
   "outputs": [],
   "source": [
    "# Cloaning the git repository\n",
    "!git clone https://github.com/facebookresearch/InferSent.git\n",
    "# Making temporary directory and appending to python path\n",
    "os.mkdir(\"InferSent/\")\n",
    "sys.path.append(\"InferSent/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "7ix08L2Qy5Mb",
    "outputId": "5c8ba946-4a3f-40cd-cc34-d94c0d774ce5"
   },
   "outputs": [],
   "source": [
    "#Downloading required dataset by InferSent\n",
    "!bash InferSent/dataset/get_data.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "guJPGQDby6JG",
    "outputId": "538b9547-a742-48c3-d0ff-3785e334a0ea"
   },
   "outputs": [],
   "source": [
    "# Downloading GloVe and FastText vectors\n",
    "!mkdir InferSent/dataset/GloVe\n",
    "!curl -Lo InferSent/dataset/GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "!unzip InferSent/dataset/GloVe/glove.840B.300d.zip -d InferSent/dataset/GloVe/\n",
    "!mkdir InferSent/dataset/fastText\n",
    "!curl -Lo InferSent/dataset/fastText/crawl-300d-2M.vec.zip https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip\n",
    "!unzip InferSent/dataset/fastText/crawl-300d-2M.vec.zip -d InferSent/dataset/fastText/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Qg3qYp1d0di5",
    "outputId": "dd735185-4014-4152-8a4a-c64ded497586"
   },
   "outputs": [],
   "source": [
    "# Downloading InferSent pretrained models\n",
    "!mkdir encoder\n",
    "!curl -Lo encoder/infersent1.pickle https://dl.fbaipublicfiles.com/infersent/infersent1.pkl\n",
    "!curl -Lo encoder/infersent2.pickle https://dl.fbaipublicfiles.com/infersent/infersent2.pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mKNbJzrgMG-S"
   },
   "source": [
    "# Fine Tuning\n",
    "1. Loading pretrined InferSent model\n",
    "2. Providing FastText vectors to the model\n",
    "3. Building the Vocab\n",
    "4. Fine tuning the model on given small corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umbXzesc1vKM"
   },
   "outputs": [],
   "source": [
    "from models import InferSent\n",
    "V = 2 \n",
    "MODEL_PATH = 'encoder/infersent2.pickle' \n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U0tiu8TY1zeC"
   },
   "outputs": [],
   "source": [
    "W2V_PATH = 'InferSent/dataset/fastText/crawl-300d-2M-subword.vec'\n",
    "infersent.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E-xp0c0R4KK5",
    "outputId": "c4a9d047-68c7-4496-df2a-036e81900231"
   },
   "outputs": [],
   "source": [
    "infersent.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DYZZhUYV4NAs"
   },
   "outputs": [],
   "source": [
    "sentences = ['Everyone really likes the newest benefits',\n",
    " 'The Government Executive articles housed on the website are not able to be searched .',\n",
    " 'I like him for the most part , but would still enjoy seeing someone beat him .',\n",
    " 'My favorite restaurants are always at least a hundred miles away from my house .',\n",
    " 'I know exactly .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVcyVEUdCZdo"
   },
   "outputs": [],
   "source": [
    "sentences = open(\"dataset_for_infersent.txt\").read().splitlines()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "MijKOsmf4pJ_",
    "outputId": "c2bd1cfe-e137-43c1-961e-98c7833463c2"
   },
   "outputs": [],
   "source": [
    "embeddings = infersent.encode(sentences, bsize=64, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zAZpnr47OgJB"
   },
   "source": [
    "# Inference\n",
    "A function to calculate cosine simillarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SgXBsJXY4wGC"
   },
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DOgIlycCOUt0"
   },
   "source": [
    "Calculating cosine simillarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KBGijfdB47Fd",
    "outputId": "0ad92585-99e1-4a52-b264-9f3d6f096769"
   },
   "outputs": [],
   "source": [
    "cosine(infersent.encode(['the cat eats.'])[0], infersent.encode(['the cat drinks.'])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8iP4KtlNsk3"
   },
   "source": [
    "Infersent also provides the importance of each token in the sentence, as shown below:\n",
    "\n",
    "![](figures/InferSent.png)\n",
    "\n",
    "Figure: Showing word importance by plotting vector generated by InferSent\n",
    "\n",
    "Here the importance of the padding is shown higher as we have not completed training a sufficiently large corpus. Once you will fine tune this model on sufficiently large data the importance for the padding and stop word will go down and the importance for the other words will increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "colab_type": "code",
    "id": "zLn8dvz85EED",
    "outputId": "4883235d-a9f2-4774-f0a1-904f400d07e2"
   },
   "outputs": [],
   "source": [
    "my_sent = 'Obama is the former president of the US'\n",
    "_, _ = infersent.visualize(my_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atYURYOT5Q_u"
   },
   "outputs": [],
   "source": [
    "embeddings = infersent.encode([\"The cat is drinking milk.\"], tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "c3ENz1KP5YHn",
    "outputId": "df98f9bc-4adf-4eb6-d481-27d9b7f69515"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of the embedding : \", embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70igPVbo5ZX5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "infersent.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
