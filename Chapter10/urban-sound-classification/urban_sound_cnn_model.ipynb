{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hINmdcD4YQGZ"
   },
   "source": [
    "# Training a Small Network\n",
    "In this Implementation, we will be using `UrbanSound8K` dataset to demonstrate how speech recognition can be done and what all components are usually required in such pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-cVDLVp2Zwxa"
   },
   "source": [
    "## Importing  Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUHre7lQ4eAF"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rx_fKJYnZUXU"
   },
   "source": [
    "#  Dataset\n",
    "\n",
    "UrbanSound8K dataset is having 8732 labeled sound recordings of 10 classes namely air_conditioner, car_horn, children_playing, dog_bark, drilling, enginge_idling, gun_shot, jackhammer, siren, and street_music. These files are in .wav format.\n",
    "\n",
    "UrbanSound8K dataset is available at https://urbansounddataset.weebly.com/urbansound8k.html. Make sure to download and uncompress this dataset in to `../data` folder before running this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPLIlUJN4euz"
   },
   "outputs": [],
   "source": [
    "#forming a panda dataframe from the metadata file\n",
    "data=pd.read_csv(\"../data/UrbanSound8K/metadata/UrbanSound8K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "6Oa7rVd54g7A",
    "outputId": "5fcf3079-7b67-4f5a-bf04-64581579ec4b"
   },
   "outputs": [],
   "source": [
    "# Looking at first few records\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "WB0QggJl4imK",
    "outputId": "f71085a3-9ce5-491c-de8e-a48ca6d287bd"
   },
   "outputs": [],
   "source": [
    "# Statistics: count of datapoints in each of the folders\n",
    "data[\"fold\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3VoNbi41Z7Ah"
   },
   "source": [
    "# Generating features\n",
    "Various features can be extracted from such sound files such as :\n",
    "1. Melspectrogram  : Compute a mel-scaled spectrogram.\n",
    "2. MFCC (Mel-frequency cepstral coefficients)\n",
    "3. chroma_stft :  Compute a chromagram from a waveform or power spectrogram.\n",
    "4. chroma_cq :  Constant-Q chromagram\n",
    "5. chroma_cens : Computes the chroma variant “Chroma Energy Normalized” (CENS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PrpVl_uJFtRz",
    "outputId": "72ac220b-c616-4bab-e040-b1f1d6be20a5"
   },
   "outputs": [],
   "source": [
    "#feature set\n",
    "#This file is of a dog bark\n",
    "y,sr=librosa.load(\"../data/UrbanSound8K/audio/fold5/100032-3-0-0.wav\")\n",
    "mfccs = librosa.feature.mfcc(y, sr, n_mfcc=40)\n",
    "melspectrogram =librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000)\n",
    "chroma_stft=librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40)\n",
    "chroma_cq =librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40)\n",
    "chroma_cens =librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40)\n",
    "melspectrogram.shape,chroma_stft.shape,chroma_cq.shape,chroma_cens.shape,mfccs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ocmXduGUblQ_"
   },
   "source": [
    "Once all these features are generated then you can viisualize each individual feature as given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJT4MUAYb22j"
   },
   "source": [
    "### MFCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "MfAip77-F78F",
    "outputId": "1c538ad2-8bb4-4baa-da58-d73dfd7b1af1"
   },
   "outputs": [],
   "source": [
    "#MFCC of dog bark\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(mfccs, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMhbOYCSb_X3"
   },
   "source": [
    "### Melspectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "DZJ3uwOfGaJH",
    "outputId": "715c8a77-c475-44b3-f8cd-feae9f6a65fe"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(librosa.power_to_db(melspectrogram,ref=np.max),y_axis='mel', fmax=8000,x_axis='time')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel spectrogram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wklQdud5cDFh"
   },
   "source": [
    "### Chromagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "tQe3FoM4GzJe",
    "outputId": "8340173b-7f54-4391-92b7-8ac335ab05bf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(chroma_stft, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('Chromagram')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Uy1gKGpcH4H"
   },
   "source": [
    "### Chroma cqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "p2k5KU1mHMiD",
    "outputId": "09bdc3dc-574a-4481-9af4-4088a5166714"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(chroma_cq, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('chroma_cqt')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jaAgyb1BcMta"
   },
   "source": [
    "### Chroma cens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "MVW_Psz3HaqB",
    "outputId": "cbbcba8a-46d2-44b4-bae8-c3f57b8119bb"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "librosa.display.specshow(chroma_cens, y_axis='chroma', x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('chroma_cens')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pMlqk-3scPnm"
   },
   "source": [
    "## Stacking all the features togather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OYTC5yz2YE2G",
    "outputId": "4cae772c-17fb-4f6c-e77c-27edaa074f6e"
   },
   "outputs": [],
   "source": [
    "#feature set\n",
    "y,sr=librosa.load(\"../data/UrbanSound8K/audio/fold5/100263-2-0-137.wav\")\n",
    "mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000).T,axis=0)\n",
    "chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "melspectrogram.shape,chroma_stft.shape,chroma_cq.shape,chroma_cens.shape,mfccs.shape\n",
    "\n",
    "#stacking and reshaping\n",
    "features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens)),(40,5))\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "07LSO5YAcYyt"
   },
   "source": [
    "# Writting features to disk\n",
    "\n",
    "This will help in one time feature generation and then can be used in N number of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4xPM6yi4nxW",
    "outputId": "56a15482-e8e3-456e-a47a-fc7f58defa0b"
   },
   "outputs": [],
   "source": [
    "#preprocessing using only mfcc\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "path=\"../data/UrbanSound8K/audio/fold\"\n",
    "for i in tqdm(range(len(data))):\n",
    "    fold_no=str(data.iloc[i][\"fold\"])\n",
    "    file=data.iloc[i][\"slice_file_name\"]\n",
    "    label=data.iloc[i][\"classID\"]\n",
    "    filename=path+fold_no+\"/\"+file\n",
    "    #print(filename)\n",
    "    y,sr=librosa.load(filename)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    #print(mfccs.shape,mfccs.max(),mfccs.min())\n",
    "    if(fold_no!='10'):\n",
    "        x_train.append(mfccs)\n",
    "        y_train.append(label)\n",
    "    else:\n",
    "        x_test.append(mfccs)\n",
    "        y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tzu_bYv_g2kg",
    "outputId": "5798b047-8994-4819-b866-d1d322611c19"
   },
   "outputs": [],
   "source": [
    "#preprocessing using entire feature set\n",
    "x_train=[]\n",
    "x_test=[]\n",
    "y_train=[]\n",
    "y_test=[]\n",
    "path=\"../data/UrbanSound8K/audio/fold\"\n",
    "for i in tqdm(range(len(data))):\n",
    "    fold_no=str(data.iloc[i][\"fold\"])\n",
    "    file=data.iloc[i][\"slice_file_name\"]\n",
    "    label=data.iloc[i][\"classID\"]\n",
    "    filename=path+fold_no+\"/\"+file\n",
    "    y,sr=librosa.load(filename)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y, sr, n_mfcc=40).T,axis=0)\n",
    "    melspectrogram = np.mean(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40,fmax=8000).T,axis=0)\n",
    "    chroma_stft=np.mean(librosa.feature.chroma_stft(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cq = np.mean(librosa.feature.chroma_cqt(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    chroma_cens = np.mean(librosa.feature.chroma_cens(y=y, sr=sr,n_chroma=40).T,axis=0)\n",
    "    features=np.reshape(np.vstack((mfccs,melspectrogram,chroma_stft,chroma_cq,chroma_cens)),(40,5))\n",
    "    if(fold_no!='10'):\n",
    "      x_train.append(features)\n",
    "      y_train.append(label)\n",
    "    else:\n",
    "      x_test.append(features)\n",
    "      y_test.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cg4r_apAeQBH"
   },
   "source": [
    "Converting features in to numpy array, these features will be then used in the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UZ67ZUVa4sy5",
    "outputId": "0e089e8f-16a2-4390-e8e0-e947401b6d91"
   },
   "outputs": [],
   "source": [
    "#converting the lists into numpy arrays\n",
    "x_train=np.array(x_train)\n",
    "x_test=np.array(x_test)\n",
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "20V6TXlx6Y3b",
    "outputId": "6067bfdf-16bf-47ff-f61c-dc0b6393c2ff"
   },
   "outputs": [],
   "source": [
    "#reshaping into 2d to save in csv format\n",
    "x_train_2d=np.reshape(x_train,(x_train.shape[0],x_train.shape[1]*x_train.shape[2]))\n",
    "x_test_2d=np.reshape(x_test,(x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
    "x_train_2d.shape,x_test_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJ2MbJzP41Xe"
   },
   "outputs": [],
   "source": [
    "#saving the data numpy arrays\n",
    "np.savetxt(\"train_data.csv\", x_train_2d, delimiter=\",\")\n",
    "np.savetxt(\"test_data.csv\",x_test_2d,delimiter=\",\")\n",
    "np.savetxt(\"train_labels.csv\",y_train,delimiter=\",\")\n",
    "np.savetxt(\"test_labels.csv\",y_test,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZHp772weevn"
   },
   "source": [
    "## Loading features for futher experimentation\n",
    "Now onwards with experimentation instead of calculating features all again, you can directly load these files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5uRr-bWZWzAD"
   },
   "outputs": [],
   "source": [
    "#extracting data from csv files into numpy arrays\n",
    "from numpy import genfromtxt\n",
    "x_train = genfromtxt('train_data.csv', delimiter=',')\n",
    "y_train = genfromtxt('train_labels.csv', delimiter=',')\n",
    "x_test = genfromtxt('test_data.csv', delimiter=',')\n",
    "y_test = genfromtxt('test_labels.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "sUE1btJWW3bw",
    "outputId": "0c2d3354-2bff-451a-e118-05f60ff0be44"
   },
   "outputs": [],
   "source": [
    "# chacking shape of train and test files\n",
    "print(\"Train shape : \",x_train.shape,\" Test shape : \",x_test.shape,\" Train label shape : \",y_train.shape,\" Test label shape : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pRgla1arfOys"
   },
   "source": [
    "# Constructing Dataloaders\n",
    "\n",
    "Data Loaders will perform following functions before loading data:\n",
    "\n",
    "1. One hot conversion of the label\n",
    "2. Reshaping to insert in to Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJQ3fU6Df-YH"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train, class_num = 10):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.class_num = class_num\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_train)\n",
    "    \n",
    "    def _to_categorical(self,y):\n",
    "        zero_array = [0  for i in range(0,self.class_num)]\n",
    "        zero_array[int(y)] = 1\n",
    "        return np.asarray(zero_array)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        selected_x = self.x_train[index]\n",
    "        selected_y = self._to_categorical(self.y_train[index])\n",
    "        return selected_x.reshape(40,5,1), selected_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ISEfGTw_gvFG"
   },
   "source": [
    "# Model\n",
    " Model is a very simple convolutional network with various layers like Convolution 2D, Batch Normalization, Mappooling, Linear/ Dense layers along with Relu activation function.\n",
    "\n",
    "The model accepts shape $ [m, 40,5,1] $ as produced by the data loader. where $m$ is the batch size. Two convolutional transformations with intermediate batch normalization and ReLu activation is applied to it. Eventually by using final shape is convergerged in to shape $[m, 10]$. where 10 is the number of class and $m$ is the batch size.\n",
    "\n",
    "This model is too simple to produce exceptionable accuracy but will provide an idea of how voice recognition pipelines are designed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79eSTzhQf-YM"
   },
   "outputs": [],
   "source": [
    "class simple_network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=40, out_channels=64, kernel_size=3, padding=1,stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.drop= nn.Dropout(0.2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, padding=1)\n",
    "        self.dense1 = nn.Linear(in_features=128*3, out_features=128*2)\n",
    "        self.dense2 = nn.Linear(in_features=128*2, out_features=10)\n",
    "        \n",
    "        \n",
    "    def forward(self, input_):\n",
    "        \"\"\n",
    "        conv1_out = self.conv1(input_)\n",
    "        conv1_out = self.bn1(conv1_out)\n",
    "        relu_applied_1 = self.relu(conv1_out)\n",
    "        maxpol_out  = self.maxpool(relu_applied_1)\n",
    "        conv_2_out = self.conv2(maxpol_out)\n",
    "        conv_2_out = self.bn2(conv_2_out)\n",
    "        relu_applied_2 = self.relu(conv_2_out)\n",
    "        drop_applied = self.drop(relu_applied_2)\n",
    "        \n",
    "        dense1_out = self.dense1(drop_applied.view(drop_applied.shape[0],drop_applied.shape[1]*drop_applied.shape[2]))\n",
    "        relu_applied_3 = self.relu(dense1_out)\n",
    "        drop_applied = self.drop(relu_applied_3)\n",
    "        \n",
    "        dense2_out = self.dense2(drop_applied)\n",
    "        relu_applied_4 = self.relu(dense2_out)\n",
    "        drop_applied = self.drop(relu_applied_4)\n",
    "        \n",
    "        return torch.softmax(drop_applied, dim =1 )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "ay1uzBSCf-YW",
    "outputId": "499c255a-d6ad-407b-c72b-b35f873feaa7"
   },
   "outputs": [],
   "source": [
    "model = simple_network()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UBLnvXTWiRBY"
   },
   "source": [
    "# Training\n",
    "## Supporting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmY3gpnqf-YZ"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    rounded_preds = torch.argmax(preds, dim=1)\n",
    "#     print(rounded_preds)\n",
    "    correct = (rounded_preds == torch.argmax(y, dim=1)).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTjC3CA0f-Yd"
   },
   "outputs": [],
   "source": [
    "def test(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0    \n",
    "    for x, y in iterator:\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        predictions = model(x.to(device))\n",
    "        loss = criterion(predictions.type(torch.FloatTensor), y.type(torch.FloatTensor))\n",
    "        acc = binary_accuracy(predictions.type(torch.FloatTensor), y.type(torch.FloatTensor))\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNYtC3-Yf-Yi"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0    \n",
    "    for x, y in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        x = x.type(torch.FloatTensor)\n",
    "        predictions = model(x.to(device))\n",
    "        loss = criterion(predictions.type(torch.FloatTensor), y.type(torch.FloatTensor))\n",
    "        acc = binary_accuracy(predictions.type(torch.FloatTensor), y.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3ystvIBiV8r"
   },
   "source": [
    "## Constructing data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BNdVNgdf-Ym"
   },
   "outputs": [],
   "source": [
    "training_set = MyDataset(x_train, y_train)\n",
    "training_generator = DataLoader(training_set,batch_size=32, shuffle=True, num_workers=1)\n",
    "test_set = MyDataset(x_test, y_test)\n",
    "test_generator = DataLoader(test_set,batch_size=32, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ij-EQ6-3gJk4"
   },
   "outputs": [],
   "source": [
    "criteria  =  nn.BCEWithLogitsLoss()\n",
    "optimizer =  torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cujah-OZii6f"
   },
   "source": [
    "## Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzdVJEnxf-Ys",
    "outputId": "12a229d6-8249-4829-e5a6-3a8ceafd3039"
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "for epoch in tqdm(range(0,100)):\n",
    "    if (epoch != 0 and epoch%20 == 0 ):\n",
    "        # chnaging learning rate for rnn_model\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr']/2\n",
    "    \n",
    "    train_loss, train_acc = train(model, training_generator, optimizer, criteria)\n",
    "    test_loss, test_acc = test(model, test_generator, criteria)\n",
    "    writer.add_scalar('Test/Loss', test_loss, epoch)\n",
    "    writer.add_scalar('Test/Accuracy', test_acc,epoch)\n",
    "    writer.add_scalar('Train/Loss', train_loss,epoch)\n",
    "    writer.add_scalar('Train/Accuracy', train_acc,epoch)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "urban_sound_cnn_model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
