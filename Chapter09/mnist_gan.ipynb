{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing GAN for MNIST\n",
    "\n",
    "In the previous recipe, we have seen various building block to construct the GAN architecture. In the recipe, we will take the MNIST dataset and design the  GAN having Generator and Discriminator. Herein we will also understand how to implement the loss function and how to provide fake and true images to the Discriminator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from IPython import display\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.autograd import Variable\n",
    "\n",
    "%matplotlib inline \n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset** :  Each MNIST image is of size 28*28. as we will be using fully connected layers so we will be flattening these image into shape 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data/', train=True, download=True, transform=transform)\n",
    "\n",
    "def train_loader(batch_size):\n",
    "    for i in range(0, len(train_dataset)-batch_size,batch_size):\n",
    "        yield torch.Tensor(np.array(train_dataset.data[i:i+batch_size])).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "**The Discriminator:**  It takes an image of size 784 and gradually shrinks to 1 by passing it through 3 fully connected layers. if the output probability is toward 1 he the input image is classified as true or else it is classified as fake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x.view(x.size(0), 784))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Generator:** The Generator looks like as given below. The generator takes a random vector of size 100. It is having 3 fully connected layers each subsequently dilate the input shape and output shape of 784   so that it can form an image of size (28*28). This is the image generated by the Generator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 100)\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "generator = Generator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining loss and Optimizer for Generator/Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "lr = 0.0002\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(discriminator, images, real_labels, fake_images, fake_labels):\n",
    "    discriminator.zero_grad()\n",
    "    outputs = discriminator(images)\n",
    "    real_loss = criterion(outputs, real_labels)\n",
    "    real_score = outputs\n",
    "    \n",
    "    outputs = discriminator(fake_images) \n",
    "    fake_loss = criterion(outputs, fake_labels)\n",
    "    fake_score = outputs\n",
    "\n",
    "    d_loss = real_loss + fake_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    return d_loss, real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(generator, discriminator_outputs, real_labels):\n",
    "    generator.zero_grad()\n",
    "    g_loss = criterion(discriminator_outputs, real_labels)\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw samples from the input distribution to inspect the generation on training \n",
    "num_test_samples = 16\n",
    "test_noise = Variable(torch.randn(num_test_samples, 100).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "**Training Process:** The overall training process has the following steps, listed below along with the code. \n",
    "\n",
    "1. Generating random vector of size 100.\n",
    "\n",
    "```python\n",
    "noise = Variable(torch.randn(images.size(0), 100).cuda())\n",
    "```\n",
    "\n",
    "2. Generating fake images by passing it through Generator, and generating labels with all zeros for these images.\n",
    "\n",
    "```python\n",
    "fake_images = generator(noise)\n",
    "fake_labels = Variable(torch.zeros(images.size(0)).cuda())\n",
    "```\n",
    "\n",
    "3. Training Discriminator by using fake image along with labels and real images along with labels. In return after training the discriminator provides the `d_loss` which is a summation of the loss generated by real images and fake images. This function also provides `real_score` and  `fake_score`. `real_score` indicates the prediction of the discriminator for images with real labels, ideally, this output should be near to 1.  `fake_score` indicates the prediction of the discriminator for images with fake labels, ideally, this output should be near to 0. Monitoring   `real_score` and fake_score provides a good idea about the convergence of the discriminator.\n",
    "\n",
    "4. Then-after fake images are generated by the generator. The label for these images is all ones(The discriminator should treat all the images as real images for loss to be 0). These fake images are passed on to the discriminator and the output generated by discriminator and the original labels are used for the loss calculation. On the basis of images generated a provided to the discriminator and label predicted by the discriminator the generator loss `g_loss` is calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create figure for plotting\n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "    ax[i,j].get_xaxis().set_visible(False)\n",
    "    ax[i,j].get_yaxis().set_visible(False)\n",
    "\n",
    "# set number of epochs and initialize figure counter\n",
    "num_epochs = 200\n",
    "num_fig = 0\n",
    "\n",
    "writter = SummaryWriter()\n",
    "\n",
    "total_iterations = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for n , images in enumerate(train_loader(batch_size=100)):\n",
    "        images = Variable(images.cuda())\n",
    "        real_labels = Variable(torch.ones(images.size(0)).cuda())\n",
    "        # Sample from generator\n",
    "        noise = Variable(torch.randn(images.size(0), 100).cuda())\n",
    "        fake_images = generator(noise)\n",
    "        fake_labels = Variable(torch.zeros(images.size(0)).cuda())\n",
    "        \n",
    "        # Train the discriminator\n",
    "        d_loss, real_score, fake_score = train_discriminator(discriminator, images, real_labels, fake_images, fake_labels)\n",
    "        \n",
    "        # Sample again from the generator and get output from discriminator\n",
    "        noise = Variable(torch.randn(images.size(0), 100).cuda())\n",
    "        fake_images = generator(noise)\n",
    "        outputs = discriminator(fake_images)\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = train_generator(generator, outputs, real_labels)\n",
    "        \n",
    "        if (n+1) % 100 == 0:\n",
    "            test_images = generator(test_noise)\n",
    "            \n",
    "            for k in range(num_test_samples):\n",
    "                i = k//4\n",
    "                j = k%4\n",
    "                ax[i,j].cla()\n",
    "                ax[i,j].imshow(test_images[k,:].data.cpu().numpy().reshape(28, 28), cmap='Greys')\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "            \n",
    "            writter.add_scalar(\"Generator/Loss\",g_loss,total_iterations)\n",
    "            writter.add_scalar(\"Discriminator/Loss\",d_loss ,total_iterations)\n",
    "            writter.add_scalar(\"Score/Real\",real_score.data.mean() ,total_iterations)\n",
    "            writter.add_scalar(\"Score/Fake\",fake_score.data.mean(),total_iterations)\n",
    "        total_iterations = total_iterations +  1\n",
    "\n",
    "fig.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training for few iteration following are the sample generated by the Generator. Training more could provide better output.\n",
    "\n",
    "![](figures/mnist_generated.png)\n",
    "\n",
    "Figure: Sample generated by Generator on the MNIST data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}