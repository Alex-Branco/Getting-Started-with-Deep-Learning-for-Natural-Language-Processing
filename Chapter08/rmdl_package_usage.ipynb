{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6QO1OV99aBK"
   },
   "source": [
    "# Understanding Random Multi-Model\n",
    "\n",
    "## Using RMDL Package \n",
    "\n",
    "Random Multi-model Deep Learning for Classification is the Framework for testing various network topology and with varying hyper-parameters on the given data to get the best model with the highest accuracy.\n",
    "\n",
    "Implementation of RMDL is provided with the git repository: https://github.com/kk7nc/RMDL\n",
    "\n",
    "RMDL solves the problem of finding the optimum deep neural network architecture by simultaneously improving the accuracy and robustness of deep learning architecture. RMDL is an ensemble consisting of 3 kinds of network architecture:\n",
    "\n",
    "1. Feed Forward Network (FFN)\n",
    "\n",
    "2. Convolution Neural Network (CNN)\n",
    "\n",
    "3. Recurrent neural network (RNN)\n",
    "\n",
    "The overall model looks as given below.\n",
    "\n",
    "![](figures/rmdl_architecture.png)\n",
    "\n",
    "Figure: RMDL schematic architecture\n",
    "\n",
    "Parameters like a number of layers in FFN, CNN, and RNN is changed randomly and defined number of random configuration are tested on the data and the beast model is given back. Having three essential components in it, RMDL can or with all type of data like text, images, video, and fully structured data. In total 9 deep learning model are generated, 3 from DNN, FFN and CNN. All of them are unique owing to random creation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nwneRhuH9YcZ"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Can be done in two ways :\n",
    "\n",
    "```bash\n",
    "!git clone https://github.com/kk7nc/RMDL.git\n",
    "python setup.y install\n",
    "```\n",
    "Or \n",
    "\n",
    "```bash \n",
    "pip install rmdl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKOzybIO-X_b"
   },
   "source": [
    "## Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdRSB_fD9Ycj"
   },
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download(\"reuters\")\n",
    "from nltk.corpus import reuters\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from RMDL import RMDL_Text as RMDL\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9H_gTKZ-nNk"
   },
   "outputs": [],
   "source": [
    "!pip install rmdl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w3AQ_trm9Ych"
   },
   "source": [
    "# Using RMDL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPzpGuXl9Yci"
   },
   "source": [
    "## Training on `reuters` data\n",
    "Reuters text classification is the benchmark data set for multi-label and multi-class classification. The dataset has 90 classes, 7769 training documents, and 3019 testing documents. More about this dataset is available here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WxQIxka-u3D"
   },
   "source": [
    "Loading and preprocessing data: Reuters corpus is present in the NLTK package, if not present can be downloaded by nltk.download(\"reuters\"). Once downloaded, train and test docs can be loaded as given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ClC8OL09Ycm"
   },
   "outputs": [],
   "source": [
    "documents = reuters.fileids()\n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"),\n",
    "                                documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"),\n",
    "                               documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8l3Ki1U-yXC"
   },
   "source": [
    "Then after x, and y for the train are separated. labels y are binarized using  `sklearn.preprocessing.MultiLabelBinarizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_GRK8Pi9Yco"
   },
   "outputs": [],
   "source": [
    "X_train = [(reuters.raw(doc_id)) for doc_id in train_docs_id]\n",
    "X_test = [(reuters.raw(doc_id)) for doc_id in test_docs_id]\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform([reuters.categories(doc_id)\n",
    "                                 for doc_id in train_docs_id])\n",
    "y_test = mlb.transform([reuters.categories(doc_id)\n",
    "                            for doc_id in test_docs_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWDThG089Ycr"
   },
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JhNnkpDR--_i"
   },
   "source": [
    "**Training the network:** Data prepared in the previous step is given to the RMDL module as shown below. RMDL.A model constraint is provided which specify how many layers a network can have for Feedforward RNN and CNN subnetwork. in below-given model network constrain are specified with variable Random_Deep. Text_Classification function takes X, Y for train and test, batch size, model constraints and embeddings file as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Nje94qx9Yct"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "sparse_categorical = 0\n",
    "n_epochs = [120, 120, 120]  ## DNN--RNN-CNN\n",
    "Random_Deep = [3, 3, 3]  ## DNN--RNN-CNN\n",
    "RMDL.Text_Classification(X_train, y_train, X_test, y_test,\n",
    "                             batch_size=batch_size,\n",
    "                             sparse_categorical=True,\n",
    "                             random_deep=Random_Deep,\n",
    "                             epochs=n_epochs,GloVe_dir=\"../embedidngs/glove.6B/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fCYU5SLT9Ycv"
   },
   "source": [
    "## Training on `20 news group` data - (Additional example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BoQERF-9Ycw"
   },
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHRKFswk9Ycz"
   },
   "outputs": [],
   "source": [
    "X_train = newsgroups_train.data\n",
    "X_test = newsgroups_test.data\n",
    "y_train = newsgroups_train.target\n",
    "y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DEQBNM1V9Yc2"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "sparse_categorical = 0\n",
    "print(len(X_train))\n",
    "n_epochs = [500, 500, 500]  ## DNN--RNN-CNN\n",
    "Random_Deep = [3,3, 3]  ## DNN--RNN-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-jRzE0x9Yc5"
   },
   "outputs": [],
   "source": [
    "RMDL.Text_Classification(X_train, y_train, X_test, y_test,\n",
    "                             batch_size=batch_size,\n",
    "                             sparse_categorical=True,\n",
    "                             random_deep=Random_Deep,\n",
    "                             epochs=n_epochs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "RMDL_package_usage.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}