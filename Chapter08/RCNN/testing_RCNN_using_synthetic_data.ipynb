{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply RCNN on synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from box_gen import get_array_with_box_at_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring data prepared in earlier notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "X = np.load(\"RCNN/data/sliding_square.npy\")\n",
    "y = np.load(\"RCNN/data/sliding_square_target.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making temporal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_X = np.zeros([X.shape[0]-1, 2, X.shape[1], X.shape[2]])\n",
    "y = y[1:]\n",
    "\n",
    "# stack the input frames in sequencial pairs\n",
    "temporal_X[:,0,:,:] = X[:-1]\n",
    "temporal_X[:,1,:,:] = X[1:]\n",
    "\n",
    "temporal_X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look a input out for sanity\n",
    "i = 18 # any random example\n",
    "ax1 = plt.subplot(331)\n",
    "ax1.imshow(temporal_X[i,0,:,:])\n",
    "ax1.set_title('X1')\n",
    "\n",
    "ax2 = plt.subplot(332)\n",
    "ax2.imshow(temporal_X[i,1,:,:])\n",
    "ax2.set_title('X2')\n",
    "\n",
    "ax3 = plt.subplot(333)\n",
    "ax3.imshow(get_array_with_box_at_pos(y[i]))\n",
    "ax3.set_title('y'+ \" = \"+ str(round(y[i],2)))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final dataset with X and y\n",
    "temporal_X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into train-test\n",
    "split_point = int(len(chron_X)*0.7)\n",
    "temporal_x_train, temporal_x_test = temporal_X[:split_point], temporal_X[split_point:]\n",
    "y_train, y_test = y[:split_point], y[split_point:]\n",
    "\n",
    "assert(len(temporal_x_train) == len(y_train))\n",
    "assert(len(temporal_x_test) == len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGRUCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Generate a convolutional GRU cell\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, kernel_size):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.reset_gate = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size, padding=padding)\n",
    "        self.update_gate = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size, padding=padding)\n",
    "        self.out_gate = nn.Conv2d(input_size + hidden_size, hidden_size, kernel_size, padding=padding)\n",
    "\n",
    "        init.orthogonal(self.reset_gate.weight)\n",
    "        init.orthogonal(self.update_gate.weight)\n",
    "        init.orthogonal(self.out_gate.weight)\n",
    "        init.constant(self.reset_gate.bias, 0.)\n",
    "        init.constant(self.update_gate.bias, 0.)\n",
    "        init.constant(self.out_gate.bias, 0.)\n",
    "\n",
    "\n",
    "    def forward(self, input_, prev_state):\n",
    "\n",
    "        # get batch and spatial sizes\n",
    "        batch_size = input_.data.size()[0]\n",
    "        spatial_size = input_.data.size()[2:]\n",
    "\n",
    "        # generate empty prev_state, if None is provided\n",
    "        if prev_state is None:\n",
    "            state_size = [batch_size, self.hidden_size] + list(spatial_size)\n",
    "            if torch.cuda.is_available():\n",
    "                prev_state = Variable(torch.zeros(state_size)).cuda()\n",
    "            else:\n",
    "                prev_state = Variable(torch.zeros(state_size))\n",
    "\n",
    "        # data size is [batch, channel, height, width]\n",
    "        stacked_inputs = torch.cat([input_, prev_state], dim=1)\n",
    "        update = F.sigmoid(self.update_gate(stacked_inputs))\n",
    "        reset = F.sigmoid(self.reset_gate(stacked_inputs))\n",
    "        out_inputs = F.tanh(self.out_gate(torch.cat([input_, prev_state * reset], dim=1)))\n",
    "        new_state = prev_state * (1 - update) + out_inputs * update\n",
    "\n",
    "        return new_state\n",
    "    \n",
    "class ConvGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_sizes, kernel_sizes, n_layers):\n",
    "        '''\n",
    "        Generates a multi-layer convolutional GRU.\n",
    "        Preserves spatial dimensions across cells, only altering depth.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size : integer. depth dimension of input tensors.\n",
    "        hidden_sizes : integer or list. depth dimensions of hidden state.\n",
    "            if integer, the same hidden size is used for all cells.\n",
    "        kernel_sizes : integer or list. sizes of Conv2d gate kernels.\n",
    "            if integer, the same kernel size is used for all cells.\n",
    "        n_layers : integer. number of chained `ConvGRUCell`.\n",
    "        '''\n",
    "\n",
    "        super(ConvGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        if type(hidden_sizes) != list:\n",
    "            self.hidden_sizes = [hidden_sizes]*n_layers\n",
    "        else:\n",
    "            assert len(hidden_sizes) == n_layers, '`hidden_sizes` must have the same length as n_layers'\n",
    "            self.hidden_sizes = hidden_sizes\n",
    "        if type(kernel_sizes) != list:\n",
    "            self.kernel_sizes = [kernel_sizes]*n_layers\n",
    "        else:\n",
    "            assert len(kernel_sizes) == n_layers, '`kernel_sizes` must have the same length as n_layers'\n",
    "            self.kernel_sizes = kernel_sizes\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        cells = []\n",
    "        for i in range(self.n_layers):\n",
    "            if i == 0:\n",
    "                input_dim = self.input_size\n",
    "            else:\n",
    "                input_dim = self.hidden_sizes[i-1]\n",
    "\n",
    "            cell = ConvGRUCell(input_dim, self.hidden_sizes[i], self.kernel_sizes[i])\n",
    "            name = 'ConvGRUCell_' + str(i).zfill(2)\n",
    "            setattr(self, name, cell)\n",
    "            cells.append(getattr(self, name))\n",
    "        \n",
    "        self.cells = cells\n",
    "        \n",
    "        # dense1 and dense2 for to converge in to output of size 1\n",
    "        self.dense1 = nn.Linear(in_features=32*5*50, out_features=100)\n",
    "        self.dense2 = nn.Linear(in_features=100, out_features=1)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        '''\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 4D input tensor. (batch, channels, height, width).\n",
    "        hidden : list of 4D hidden state representations. (batch, channels, height, width).\n",
    "        Returns\n",
    "        -------\n",
    "        upd_hidden : 5D hidden representation. (layer, batch, channels, height, width).\n",
    "        '''\n",
    "        if not hidden:\n",
    "            hidden = [None]*self.n_layers\n",
    "\n",
    "        input_ = x\n",
    "        upd_hidden = []\n",
    "        for layer_idx in range(self.n_layers):\n",
    "            cell = self.cells[layer_idx]\n",
    "            cell_hidden = hidden[layer_idx]\n",
    "            # pass through layer\n",
    "            upd_cell_hidden = cell(input_, cell_hidden)\n",
    "            upd_hidden.append(upd_cell_hidden.detach().numpy())\n",
    "            # update input_ to the last updated hidden layer for next pass\n",
    "            input_ = upd_cell_hidden\n",
    "        output_tensor = torch.Tensor(np.array(upd_hidden))\n",
    "        batch_size = output_tensor.shape[1]\n",
    "        reshaped_output = output_tensor.view(batch_size, -1)\n",
    "        # passing through dense layers to \n",
    "        dense1_out = self.dense1(reshaped_output)\n",
    "        dense2_out = self.dense2(dense1_out)\n",
    "        \n",
    "        return dense2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvGRU(input_size=2, hidden_sizes=[32],kernel_sizes=[3], n_layers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining loss and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "losses  = []\n",
    "for i in range(epochs):\n",
    "    x = Variable(torch.Tensor(temporal_x_train).type(torch.FloatTensor))\n",
    "    optimizer.zero_grad()\n",
    "    predicted = model(x)\n",
    "    loss = criteria(predicted, Variable(torch.Tensor(y_train.reshape(-1,1))))\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.title(\"Decrease in loss as the training progresses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test in forward / backward direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "all_predictions = []\n",
    "all_label = []\n",
    "for frame, output in zip(temporal_x_test, y_test):\n",
    "    x = Variable(torch.Tensor(frame).unsqueeze(0).type(torch.FloatTensor))\n",
    "    predicted = model(x)\n",
    "    \n",
    "    ax1 = plt.subplot(441)\n",
    "    ax1.imshow(frame[0])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    ax1.set_title('X1')\n",
    "    plt.yticks([])\n",
    "\n",
    "    ax2 = plt.subplot(442)\n",
    "    ax2.imshow(frame[1])\n",
    "    ax2.set_title('X2')\n",
    "    plt.yticks([])\n",
    "\n",
    "    ax3 = plt.subplot(443)\n",
    "    ax3.imshow(get_array_with_box_at_pos(predicted.detach().numpy()[0][0]))\n",
    "    ax3.set_title('y_pred'+ \" = \"+ str(round(predicted.detach().numpy()[0][0],2)))\n",
    "    plt.yticks([])\n",
    "    \n",
    "    ax4 = plt.subplot(444)\n",
    "    ax4.imshow(get_array_with_box_at_pos(output))\n",
    "    ax4.set_title('y'+ \" = \"+ str(round(output,2)))\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "    all_predictions.append(predicted.item())\n",
    "    all_label.append(output)\n",
    "\n",
    "test_loss += mean_squared_error(all_predictions, all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The final test loss : \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
