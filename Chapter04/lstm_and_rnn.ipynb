{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Hwyb4fS6l-J"
   },
   "source": [
    "# Understanding Advance RNN units\n",
    "\n",
    "In this Implemetation, we will be comparing some of the advanced RNN units, like Long Short term memory (LSTM) and Gated Recurrent Units (GRU).\n",
    "\n",
    "\n",
    "LSTM units have very intuitive structure. It has two internal states, whereas vanilla RNN has only one hidden state. The cell state in the LSTM is like a conveyor belt which runs on the top of the unit as shown in the diagram. The cell state is highly regulated by gates attached to it. Gates are the way to let the information through. LSTM has three gates to control the information flow.\n",
    "\n",
    "![](figures/LSTM.png) \n",
    "\n",
    "\n",
    "Figure: Showing various Gates present in LSTM.\n",
    "\n",
    "\n",
    "**Forget gate**: It regulates the information flow. A sigmoid gate looks at the input  and previous hidden state .  The sigmoid output value of  1 means let everything go through and 0 means nothing to get through. \n",
    "\n",
    "$$ f_t = \\sigma_g (W_f[W_{t-1},x_t] + b_f)  $$\n",
    "\n",
    "To keep or not is gradually learned by weights and bias attached to forget gate. \n",
    "\n",
    "**Input gate: **Next is the input gate that decides what information we are going to keep in the cell state. The input gate has two inputs one is controlled by sigmoid and another is controlled by tanh. The input gate is defined by below-given equations.\n",
    "\n",
    "$$i_t = \\sigma_g (W_i\\bullet [h_{t-1}, x_t]  + b_i) \\\\\n",
    "\\widetilde{C}_t = tanh(W_c\\bullet [h_{t-1}, x_t] + b_c) $$\n",
    "\n",
    "Output gate: It decides what information to let through according to cell state and hidden state. A sigmoid gate decides what information from the hidden state goes to output. Tanh decides what information from cell state goes to output gate. Output gate can be mathematically represented as follows: \n",
    "\n",
    "$$o_t = \\sigma_g (W_o[h_{t-1}, x_t]+ b_o) \\\\\n",
    "h_t = o_t * tanh(C_t) $$\n",
    "\n",
    "The information controlled by gate then merges into the cell state as shown in the below-given equation.\n",
    "\n",
    "$$c_t = f_t \\circ c_{t-1} + i_t \\circ \\widetilde C_t $$\n",
    "\n",
    "LSTM can be very simply implemented using Pytorch. Pytorch has a function LSTM and it takes similar input shape as described in case of vanilla RNN,  it can be used as follow. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqQ1RzJ08OWU"
   },
   "source": [
    "# Importing Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "6TEFf4WfvLRW",
    "outputId": "2393f08d-fffb-454b-851b-e07ed17f2bca"
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import tarfile\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('popular')\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FdXgOS6nkHF"
   },
   "source": [
    "# Downloading required datasets\n",
    "To demonstrate how embeddings can help, we will be conducting an experiment on sentiment analysis task. I have used movie review dataset having 5331 positive and 5331 negative processed sentences. The entire experiment is divided into 5 sections. \n",
    "\n",
    "Downloading Dataset: Above discussed dataset is available at http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JtpoPziv8GJO"
   },
   "outputs": [],
   "source": [
    "data_exists = os.path.isfile('data/rt-polaritydata.tar.gz')\n",
    "if not  data_exists:\n",
    "    urllib.request.urlretrieve(\"http://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.tar.gz\",\n",
    "                                       \"data/rt-polaritydata.tar.gz\")\n",
    "    tar = tarfile.open(\"data/rt-polaritydata.tar.gz\")\n",
    "    tar.extractall(path='data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pG6zlPuBnkHI"
   },
   "source": [
    "# Downloading embedding\n",
    "The pre-trained embeddings are available and can be easily used in our model.  we will be using the FastText vector trained on the wiki news corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7YAlpTCP6gy"
   },
   "outputs": [],
   "source": [
    "embed_exists = os.path.isfile('../embeddings/wiki-news-300d-1M.vec.zip')\n",
    "if embed_exists:\n",
    "    print(\"FastText embeddings exists, if not downloaded properly, then delete the `../embeddings/wiki-news-300d-1M.vec.zip\")\n",
    "    urllib.request.urlretrieve(\"https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\",\"../embeddings/wiki-news-300d-1M.vec.zip\")\n",
    "    zip_ref = zipfile.ZipFile(\"../embeddings/wiki-news-300d-1M.vec.zip\", 'r')\n",
    "    zip_ref.extractall(\"../embeddings/\")\n",
    "    zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13BKiVJhnkHM"
   },
   "source": [
    "# Preprocessing\n",
    "I am using TorchText to preprocess downloaded data. The preprocessing includes following steps:\n",
    "\n",
    "- Reading and parsing data \n",
    "- Defining sentiment and label fields\n",
    "- Dividing data into train, valid and test subset\n",
    "- forming the train, valid and test iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k3sTlJzyvLRb"
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "split = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "85Uzm_t7vLRe"
   },
   "outputs": [],
   "source": [
    "data_block = []\n",
    "negative_data  = open('data/rt-polaritydata/rt-polarity.neg',encoding='utf8',errors='ignore').read().splitlines()\n",
    "for i in negative_data:\n",
    "        data_block.append({\"sentiment\":str(i.strip()),\"label\" : 0}) \n",
    "positve_data  = open('data/rt-polaritydata/rt-polarity.pos',encoding='utf8',errors='ignore').read().splitlines()\n",
    "for i in positve_data:\n",
    "        data_block.append({\"sentiment\":str(i.strip()),\"label\" : 1}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzntAD2CvLRi"
   },
   "outputs": [],
   "source": [
    "random.shuffle(data_block)\n",
    "\n",
    "train_file = open('data/train.json', 'w')\n",
    "test_file = open('data/test.json', 'w')\n",
    "for i in  range(0,int(len(data_block)*split)):\n",
    "    train_file.write(str(json.dumps(data_block[i]))+\"\\n\")\n",
    "for i in  range(int(len(data_block)*split),len(data_block)):\n",
    "    test_file.write(str(json.dumps(data_block[i]))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2xfhN6avLRl"
   },
   "outputs": [],
   "source": [
    "def tokenize(sentiments):\n",
    "#     print(sentiments)\n",
    "    return sentiments\n",
    "def pad_to_equal(x):\n",
    "    if len(x) < 61:\n",
    "        return x + ['<pad>' for i in range(0, 61 - len(x))]\n",
    "    else:\n",
    "        return x[:61]\n",
    "def to_categorical(x):\n",
    "    if x == 1:\n",
    "        return [0,1]\n",
    "    if x == 0:\n",
    "        return [1,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8JZt1mBvLRp"
   },
   "outputs": [],
   "source": [
    "SENTIMENT = data.Field(sequential=True , preprocessing =pad_to_equal , use_vocab = True, lower=True)\n",
    "LABEL = data.Field(is_target=True,use_vocab = False, sequential=False, preprocessing =to_categorical)\n",
    "fields = {'sentiment': ('sentiment', SENTIMENT), 'label': ('label', LABEL)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fq8L7GjZvLRu"
   },
   "outputs": [],
   "source": [
    "train_data , test_data = data.TabularDataset.splits(\n",
    "                            path = 'data',\n",
    "                            train = 'train.json',\n",
    "                            test = 'test.json',\n",
    "                            format = 'json',\n",
    "                            fields = fields                                \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "3WzzpHkXvLRy",
    "outputId": "03d3f95b-d6ea-4bdb-bda8-287dbc22e731"
   },
   "outputs": [],
   "source": [
    "print(\"Printing an example data : \",vars(train_data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUYeX3eenkHi"
   },
   "source": [
    "**Splitting data in to test and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FEZRHuB7vLR3"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3CFyFa5_vLR7",
    "outputId": "744e9de0-82bf-4469-f48d-b37a70675b26"
   },
   "outputs": [],
   "source": [
    "print('Number of training examples: ', len(train_data))\n",
    "print('Number of validation examples: ', len(valid_data))\n",
    "print('Number of testing examples: ',len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWod-X4lnkHp"
   },
   "source": [
    "**Loading Embedding to vocab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUF_n6AivLSY"
   },
   "outputs": [],
   "source": [
    "vec = vocab.Vectors(name = \"glove.840B.300d.txt\",cache = \"../embeddings/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_J_s0L0ovLSd"
   },
   "outputs": [],
   "source": [
    "SENTIMENT.build_vocab(train_data, valid_data, test_data, max_size=100000, vectors=vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mqWn6jGWnkHy"
   },
   "source": [
    "**Constructing Iterators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "qZKthaRvvLSj",
    "outputId": "052822da-5515-4b0c-9042-1e8fa0ddf296"
   },
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = data.Iterator.splits(\n",
    "        (train_data, valid_data, test_data), sort_key=lambda x: len(x.sentiment),\n",
    "        batch_sizes=(32,32,32), device=-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLTLVlHQvLSr"
   },
   "outputs": [],
   "source": [
    "sentiment_vocab = SENTIMENT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X46F3yZE0Gx9",
    "outputId": "80748d07-5caa-4a10-ff38-b912e05d0dff"
   },
   "outputs": [],
   "source": [
    "sentiment_vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlpB4gbKnkIB"
   },
   "source": [
    "# Training\n",
    " Training will be conducted for two models one with Vanilla RNN  pre-trained embedding and one with LSTM. I am using FastText embeddings trained on wikipedia corpus with a vector size of 300. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8sGtYZ1-Bkl"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    rounded_preds = torch.argmax(preds, dim=1)\n",
    "#     print(rounded_preds)\n",
    "    correct = (rounded_preds == torch.argmax(y, dim=1)).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QqPGWHX5B9Gj"
   },
   "source": [
    "## Training using Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHhzpI4D41ZL"
   },
   "outputs": [],
   "source": [
    "class VANILA_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, sentiment_vocab):\n",
    "        super(VANILA_RNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        # and apply dropout\n",
    "\n",
    "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        return torch.softmax(self.fc(hidden.squeeze(0)),dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRl3m_aN9mQN"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SENTIMENT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 2\n",
    "BATCH_SIZE = 32\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "\n",
    "vanila_rnn = VANILA_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, sentiment_vocab)\n",
    "vanila_rnn = vanila_rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcUokNSt9yGl"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(vanila_rnn.parameters(), lr=0.1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mSUXx7X6-EOK"
   },
   "outputs": [],
   "source": [
    "def train(vanila_rnn, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    vanila_rnn.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()       \n",
    "        predictions = vanila_rnn(batch.sentiment.to(device)).squeeze(1)\n",
    "        loss = criterion(predictions.type(torch.FloatTensor), batch.label.type(torch.FloatTensor))\n",
    "        acc = binary_accuracy(predictions.type(torch.FloatTensor), batch.label.type(torch.FloatTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1734
    },
    "colab_type": "code",
    "id": "qkqjMC8e-Xzm",
    "outputId": "2d19c6c9-f14c-47bc-985d-089ee730afb6"
   },
   "outputs": [],
   "source": [
    "rnn_loss = []\n",
    "rnn_accuracy = []\n",
    "for i in tqdm(range(0,100)):\n",
    "    loss, accuracy =  train(vanila_rnn, train_iter, optimizer, criterion)\n",
    "    print(\"Loss : \",loss, \"Accuracy : \", accuracy )\n",
    "    rnn_loss.append(loss)\n",
    "    rnn_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPqBr_3LCFTp"
   },
   "source": [
    "## Training using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iAEv9frrjlMN"
   },
   "outputs": [],
   "source": [
    "class LSTM_RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, sentiment_vocab):\n",
    "        super(LSTM_RNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell)= self.rnn(embedded)\n",
    "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
    "        # and apply dropout\n",
    "\n",
    "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2GsTDmPjlMS"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SENTIMENT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 2\n",
    "BATCH_SIZE = 32\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "\n",
    "lstm_rnn = LSTM_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, sentiment_vocab)\n",
    "lstm_rnn = lstm_rnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LD-nHs1Qz8AT"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(lstm_rnn.parameters(), lr=0.1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1734
    },
    "colab_type": "code",
    "id": "TLdlbaND-bvv",
    "outputId": "a752aa6b-84b0-4792-eb95-fd510dee988f"
   },
   "outputs": [],
   "source": [
    "lstm_loss = []\n",
    "lstm_accuracy = []\n",
    "for i in tqdm(range(0,100)):\n",
    "    loss, accuracy =  train(lstm_rnn, train_iter, optimizer, criterion)\n",
    "    print(\"Loss : \",loss, \"Accuracy : \", accuracy )\n",
    "    lstm_loss.append(loss)\n",
    "    lstm_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CFT-Uv9UCOcm"
   },
   "source": [
    "## Comparision\n",
    "When the sentiment analysis test was run for 100 epochs. I found that the performance of the LSTM is recommendable. \n",
    "\n",
    "![](figures/LSTM_RNN.png)\n",
    "Figure: Showing Difference between accuracy when LSTM and RNN used for text classification\n",
    "\n",
    "The accuracy of train data was 95+% with LSTM and was around 70% with RNN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "mkMZnGsRDgO0",
    "outputId": "ce0b86fc-af53-4bfb-f89a-7bd5f278c5cf"
   },
   "outputs": [],
   "source": [
    "plt.plot(rnn_accuracy , label = \"RNN Accuracy\")\n",
    "plt.plot(lstm_accuracy , label = \"LSTM Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAqzXv9WLRfh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_and_RNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}